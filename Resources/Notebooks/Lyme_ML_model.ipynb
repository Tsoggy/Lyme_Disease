{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2e295be0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e3e5a376",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Dependencies \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from collections import Counter\n",
    "from sklearn.metrics import balanced_accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from imblearn.metrics import classification_report_imbalanced"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a28cf88",
   "metadata": {},
   "source": [
    "## Preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "212a906c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in files\n",
    "\n",
    "file_path = 'Data/Cleaned_Data/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "66b13f07",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3142, 10)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>FIPS</th>\n",
       "      <th>State</th>\n",
       "      <th>County</th>\n",
       "      <th>Lifespan_Rank</th>\n",
       "      <th>Life_Quality_Rank</th>\n",
       "      <th>Health_Behaviors_Rank</th>\n",
       "      <th>Clinical_Care_Rank</th>\n",
       "      <th>Social_Economic_Factors_Rank</th>\n",
       "      <th>Physical_Environment_Rank</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1001</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>Autauga</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>15</td>\n",
       "      <td>14</td>\n",
       "      <td>5</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1003</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>Baldwin</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1005</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>Barbour</td>\n",
       "      <td>14</td>\n",
       "      <td>48</td>\n",
       "      <td>53</td>\n",
       "      <td>30</td>\n",
       "      <td>61</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1007</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>Bibb</td>\n",
       "      <td>47</td>\n",
       "      <td>24</td>\n",
       "      <td>38</td>\n",
       "      <td>16</td>\n",
       "      <td>38</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>1009</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>Blount</td>\n",
       "      <td>36</td>\n",
       "      <td>14</td>\n",
       "      <td>10</td>\n",
       "      <td>41</td>\n",
       "      <td>15</td>\n",
       "      <td>53</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  FIPS    State   County Lifespan_Rank Life_Quality_Rank  \\\n",
       "0           1  1001  Alabama  Autauga             8                 5   \n",
       "1           2  1003  Alabama  Baldwin             3                 4   \n",
       "2           3  1005  Alabama  Barbour            14                48   \n",
       "3           4  1007  Alabama     Bibb            47                24   \n",
       "4           5  1009  Alabama   Blount            36                14   \n",
       "\n",
       "  Health_Behaviors_Rank Clinical_Care_Rank Social_Economic_Factors_Rank  \\\n",
       "0                    15                 14                            5   \n",
       "1                     3                  4                            3   \n",
       "2                    53                 30                           61   \n",
       "3                    38                 16                           38   \n",
       "4                    10                 41                           15   \n",
       "\n",
       "  Physical_Environment_Rank  \n",
       "0                        50  \n",
       "1                        62  \n",
       "2                        32  \n",
       "3                        31  \n",
       "4                        53  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read in Health Ranking Data\n",
    "df = pd.read_csv(f\"../../{file_path}County_Health_All_Factors.csv\")\n",
    "print(df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "44ceaabc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3033, 25)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>County</th>\n",
       "      <th>State</th>\n",
       "      <th>FIPS</th>\n",
       "      <th>Lyme_Disease_Incidence_Reported</th>\n",
       "      <th>Population</th>\n",
       "      <th>%&lt;18_Yrs_Old</th>\n",
       "      <th>%65_Yrs_Old_and_over</th>\n",
       "      <th>Income($)</th>\n",
       "      <th>African_American(Count)</th>\n",
       "      <th>African_American(%)</th>\n",
       "      <th>...</th>\n",
       "      <th>Native_Hawaiian/Other_Pacific_Islander(%)</th>\n",
       "      <th>Hispanic(Count)</th>\n",
       "      <th>Hispanic(%)</th>\n",
       "      <th>Non-Hispanic_White_(Count)</th>\n",
       "      <th>Non-Hispanic_White(%)</th>\n",
       "      <th>Female(%)</th>\n",
       "      <th>Rural(Count)</th>\n",
       "      <th>Rural(%)</th>\n",
       "      <th>Life_Expectancy</th>\n",
       "      <th>Deaths(Count)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Autauga</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>1001</td>\n",
       "      <td>1.0</td>\n",
       "      <td>55504</td>\n",
       "      <td>23.94</td>\n",
       "      <td>15.12</td>\n",
       "      <td>$58343.00</td>\n",
       "      <td>10687</td>\n",
       "      <td>19.25</td>\n",
       "      <td>...</td>\n",
       "      <td>0.10</td>\n",
       "      <td>1586</td>\n",
       "      <td>2.86</td>\n",
       "      <td>41336</td>\n",
       "      <td>74.47</td>\n",
       "      <td>51.34</td>\n",
       "      <td>22921.0</td>\n",
       "      <td>42.00</td>\n",
       "      <td>76.33</td>\n",
       "      <td>815.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Baldwin</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>1003</td>\n",
       "      <td>0.0</td>\n",
       "      <td>212628</td>\n",
       "      <td>21.85</td>\n",
       "      <td>19.95</td>\n",
       "      <td>$56607.00</td>\n",
       "      <td>19037</td>\n",
       "      <td>8.95</td>\n",
       "      <td>...</td>\n",
       "      <td>0.07</td>\n",
       "      <td>9675</td>\n",
       "      <td>4.55</td>\n",
       "      <td>176582</td>\n",
       "      <td>83.05</td>\n",
       "      <td>51.45</td>\n",
       "      <td>77060.0</td>\n",
       "      <td>42.28</td>\n",
       "      <td>78.60</td>\n",
       "      <td>2827.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Barbour</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>1005</td>\n",
       "      <td>1.0</td>\n",
       "      <td>25270</td>\n",
       "      <td>20.76</td>\n",
       "      <td>18.82</td>\n",
       "      <td>$32490.00</td>\n",
       "      <td>12115</td>\n",
       "      <td>47.94</td>\n",
       "      <td>...</td>\n",
       "      <td>0.19</td>\n",
       "      <td>1063</td>\n",
       "      <td>4.21</td>\n",
       "      <td>11613</td>\n",
       "      <td>45.96</td>\n",
       "      <td>47.23</td>\n",
       "      <td>18613.0</td>\n",
       "      <td>67.79</td>\n",
       "      <td>75.78</td>\n",
       "      <td>451.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Bibb</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>1007</td>\n",
       "      <td>0.0</td>\n",
       "      <td>22668</td>\n",
       "      <td>20.61</td>\n",
       "      <td>16.02</td>\n",
       "      <td>$45795.00</td>\n",
       "      <td>4864</td>\n",
       "      <td>21.46</td>\n",
       "      <td>...</td>\n",
       "      <td>0.11</td>\n",
       "      <td>598</td>\n",
       "      <td>2.64</td>\n",
       "      <td>16842</td>\n",
       "      <td>74.30</td>\n",
       "      <td>46.45</td>\n",
       "      <td>15663.0</td>\n",
       "      <td>68.35</td>\n",
       "      <td>73.93</td>\n",
       "      <td>445.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Blount</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>1009</td>\n",
       "      <td>0.0</td>\n",
       "      <td>58013</td>\n",
       "      <td>23.35</td>\n",
       "      <td>17.84</td>\n",
       "      <td>$48253.00</td>\n",
       "      <td>847</td>\n",
       "      <td>1.46</td>\n",
       "      <td>...</td>\n",
       "      <td>0.12</td>\n",
       "      <td>5549</td>\n",
       "      <td>9.57</td>\n",
       "      <td>50439</td>\n",
       "      <td>86.94</td>\n",
       "      <td>50.69</td>\n",
       "      <td>51562.0</td>\n",
       "      <td>89.95</td>\n",
       "      <td>74.60</td>\n",
       "      <td>1050.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    County    State  FIPS  Lyme_Disease_Incidence_Reported  Population  \\\n",
       "0  Autauga  Alabama  1001                              1.0       55504   \n",
       "1  Baldwin  Alabama  1003                              0.0      212628   \n",
       "2  Barbour  Alabama  1005                              1.0       25270   \n",
       "3     Bibb  Alabama  1007                              0.0       22668   \n",
       "4   Blount  Alabama  1009                              0.0       58013   \n",
       "\n",
       "   %<18_Yrs_Old  %65_Yrs_Old_and_over  Income($)  African_American(Count)  \\\n",
       "0         23.94                 15.12  $58343.00                    10687   \n",
       "1         21.85                 19.95  $56607.00                    19037   \n",
       "2         20.76                 18.82  $32490.00                    12115   \n",
       "3         20.61                 16.02  $45795.00                     4864   \n",
       "4         23.35                 17.84  $48253.00                      847   \n",
       "\n",
       "   African_American(%)  ...  Native_Hawaiian/Other_Pacific_Islander(%)  \\\n",
       "0                19.25  ...                                       0.10   \n",
       "1                 8.95  ...                                       0.07   \n",
       "2                47.94  ...                                       0.19   \n",
       "3                21.46  ...                                       0.11   \n",
       "4                 1.46  ...                                       0.12   \n",
       "\n",
       "   Hispanic(Count)  Hispanic(%)  Non-Hispanic_White_(Count)  \\\n",
       "0             1586         2.86                       41336   \n",
       "1             9675         4.55                      176582   \n",
       "2             1063         4.21                       11613   \n",
       "3              598         2.64                       16842   \n",
       "4             5549         9.57                       50439   \n",
       "\n",
       "   Non-Hispanic_White(%)  Female(%)  Rural(Count)  Rural(%)  Life_Expectancy  \\\n",
       "0                  74.47      51.34       22921.0     42.00            76.33   \n",
       "1                  83.05      51.45       77060.0     42.28            78.60   \n",
       "2                  45.96      47.23       18613.0     67.79            75.78   \n",
       "3                  74.30      46.45       15663.0     68.35            73.93   \n",
       "4                  86.94      50.69       51562.0     89.95            74.60   \n",
       "\n",
       "   Deaths(Count)  \n",
       "0          815.0  \n",
       "1         2827.0  \n",
       "2          451.0  \n",
       "3          445.0  \n",
       "4         1050.0  \n",
       "\n",
       "[5 rows x 25 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read in the Merged Data\n",
    "df2 = pd.read_csv(f\"../../{file_path}Merged_Demographic_Data.csv\")\n",
    "print(df2.shape)\n",
    "df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "895c25c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3142, 34)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>FIPS</th>\n",
       "      <th>State_x</th>\n",
       "      <th>County_x</th>\n",
       "      <th>Lifespan_Rank</th>\n",
       "      <th>Life_Quality_Rank</th>\n",
       "      <th>Health_Behaviors_Rank</th>\n",
       "      <th>Clinical_Care_Rank</th>\n",
       "      <th>Social_Economic_Factors_Rank</th>\n",
       "      <th>Physical_Environment_Rank</th>\n",
       "      <th>...</th>\n",
       "      <th>Native_Hawaiian/Other_Pacific_Islander(%)</th>\n",
       "      <th>Hispanic(Count)</th>\n",
       "      <th>Hispanic(%)</th>\n",
       "      <th>Non-Hispanic_White_(Count)</th>\n",
       "      <th>Non-Hispanic_White(%)</th>\n",
       "      <th>Female(%)</th>\n",
       "      <th>Rural(Count)</th>\n",
       "      <th>Rural(%)</th>\n",
       "      <th>Life_Expectancy</th>\n",
       "      <th>Deaths(Count)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1001</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>Autauga</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>15</td>\n",
       "      <td>14</td>\n",
       "      <td>5</td>\n",
       "      <td>50</td>\n",
       "      <td>...</td>\n",
       "      <td>0.10</td>\n",
       "      <td>1586.0</td>\n",
       "      <td>2.86</td>\n",
       "      <td>41336.0</td>\n",
       "      <td>74.47</td>\n",
       "      <td>51.34</td>\n",
       "      <td>22921.0</td>\n",
       "      <td>42.00</td>\n",
       "      <td>76.33</td>\n",
       "      <td>815.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1003</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>Baldwin</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>62</td>\n",
       "      <td>...</td>\n",
       "      <td>0.07</td>\n",
       "      <td>9675.0</td>\n",
       "      <td>4.55</td>\n",
       "      <td>176582.0</td>\n",
       "      <td>83.05</td>\n",
       "      <td>51.45</td>\n",
       "      <td>77060.0</td>\n",
       "      <td>42.28</td>\n",
       "      <td>78.60</td>\n",
       "      <td>2827.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1005</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>Barbour</td>\n",
       "      <td>14</td>\n",
       "      <td>48</td>\n",
       "      <td>53</td>\n",
       "      <td>30</td>\n",
       "      <td>61</td>\n",
       "      <td>32</td>\n",
       "      <td>...</td>\n",
       "      <td>0.19</td>\n",
       "      <td>1063.0</td>\n",
       "      <td>4.21</td>\n",
       "      <td>11613.0</td>\n",
       "      <td>45.96</td>\n",
       "      <td>47.23</td>\n",
       "      <td>18613.0</td>\n",
       "      <td>67.79</td>\n",
       "      <td>75.78</td>\n",
       "      <td>451.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1007</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>Bibb</td>\n",
       "      <td>47</td>\n",
       "      <td>24</td>\n",
       "      <td>38</td>\n",
       "      <td>16</td>\n",
       "      <td>38</td>\n",
       "      <td>31</td>\n",
       "      <td>...</td>\n",
       "      <td>0.11</td>\n",
       "      <td>598.0</td>\n",
       "      <td>2.64</td>\n",
       "      <td>16842.0</td>\n",
       "      <td>74.30</td>\n",
       "      <td>46.45</td>\n",
       "      <td>15663.0</td>\n",
       "      <td>68.35</td>\n",
       "      <td>73.93</td>\n",
       "      <td>445.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>1009</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>Blount</td>\n",
       "      <td>36</td>\n",
       "      <td>14</td>\n",
       "      <td>10</td>\n",
       "      <td>41</td>\n",
       "      <td>15</td>\n",
       "      <td>53</td>\n",
       "      <td>...</td>\n",
       "      <td>0.12</td>\n",
       "      <td>5549.0</td>\n",
       "      <td>9.57</td>\n",
       "      <td>50439.0</td>\n",
       "      <td>86.94</td>\n",
       "      <td>50.69</td>\n",
       "      <td>51562.0</td>\n",
       "      <td>89.95</td>\n",
       "      <td>74.60</td>\n",
       "      <td>1050.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>1011</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>Bullock</td>\n",
       "      <td>53</td>\n",
       "      <td>58</td>\n",
       "      <td>65</td>\n",
       "      <td>62</td>\n",
       "      <td>64</td>\n",
       "      <td>24</td>\n",
       "      <td>...</td>\n",
       "      <td>0.78</td>\n",
       "      <td>850.0</td>\n",
       "      <td>8.25</td>\n",
       "      <td>2196.0</td>\n",
       "      <td>21.30</td>\n",
       "      <td>45.53</td>\n",
       "      <td>5607.0</td>\n",
       "      <td>51.37</td>\n",
       "      <td>73.12</td>\n",
       "      <td>205.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>1013</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>Butler</td>\n",
       "      <td>63</td>\n",
       "      <td>56</td>\n",
       "      <td>56</td>\n",
       "      <td>52</td>\n",
       "      <td>55</td>\n",
       "      <td>8</td>\n",
       "      <td>...</td>\n",
       "      <td>0.05</td>\n",
       "      <td>285.0</td>\n",
       "      <td>1.44</td>\n",
       "      <td>10229.0</td>\n",
       "      <td>51.60</td>\n",
       "      <td>53.43</td>\n",
       "      <td>14921.0</td>\n",
       "      <td>71.23</td>\n",
       "      <td>73.51</td>\n",
       "      <td>393.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>1015</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>Calhoun</td>\n",
       "      <td>55</td>\n",
       "      <td>10</td>\n",
       "      <td>28</td>\n",
       "      <td>34</td>\n",
       "      <td>27</td>\n",
       "      <td>41</td>\n",
       "      <td>...</td>\n",
       "      <td>0.11</td>\n",
       "      <td>4302.0</td>\n",
       "      <td>3.75</td>\n",
       "      <td>82961.0</td>\n",
       "      <td>72.31</td>\n",
       "      <td>51.93</td>\n",
       "      <td>39955.0</td>\n",
       "      <td>33.70</td>\n",
       "      <td>73.10</td>\n",
       "      <td>2333.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>1017</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>Chambers</td>\n",
       "      <td>42</td>\n",
       "      <td>53</td>\n",
       "      <td>57</td>\n",
       "      <td>25</td>\n",
       "      <td>37</td>\n",
       "      <td>46</td>\n",
       "      <td>...</td>\n",
       "      <td>0.04</td>\n",
       "      <td>822.0</td>\n",
       "      <td>2.44</td>\n",
       "      <td>18710.0</td>\n",
       "      <td>55.50</td>\n",
       "      <td>52.13</td>\n",
       "      <td>16816.0</td>\n",
       "      <td>49.15</td>\n",
       "      <td>74.12</td>\n",
       "      <td>691.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>1019</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>Cherokee</td>\n",
       "      <td>43</td>\n",
       "      <td>8</td>\n",
       "      <td>12</td>\n",
       "      <td>54</td>\n",
       "      <td>19</td>\n",
       "      <td>43</td>\n",
       "      <td>...</td>\n",
       "      <td>0.03</td>\n",
       "      <td>425.0</td>\n",
       "      <td>1.64</td>\n",
       "      <td>23707.0</td>\n",
       "      <td>91.69</td>\n",
       "      <td>50.32</td>\n",
       "      <td>22282.0</td>\n",
       "      <td>85.74</td>\n",
       "      <td>74.35</td>\n",
       "      <td>575.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 34 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  FIPS  State_x  County_x Lifespan_Rank Life_Quality_Rank  \\\n",
       "0           1  1001  Alabama   Autauga             8                 5   \n",
       "1           2  1003  Alabama   Baldwin             3                 4   \n",
       "2           3  1005  Alabama   Barbour            14                48   \n",
       "3           4  1007  Alabama      Bibb            47                24   \n",
       "4           5  1009  Alabama    Blount            36                14   \n",
       "5           6  1011  Alabama   Bullock            53                58   \n",
       "6           7  1013  Alabama    Butler            63                56   \n",
       "7           8  1015  Alabama   Calhoun            55                10   \n",
       "8           9  1017  Alabama  Chambers            42                53   \n",
       "9          10  1019  Alabama  Cherokee            43                 8   \n",
       "\n",
       "  Health_Behaviors_Rank Clinical_Care_Rank Social_Economic_Factors_Rank  \\\n",
       "0                    15                 14                            5   \n",
       "1                     3                  4                            3   \n",
       "2                    53                 30                           61   \n",
       "3                    38                 16                           38   \n",
       "4                    10                 41                           15   \n",
       "5                    65                 62                           64   \n",
       "6                    56                 52                           55   \n",
       "7                    28                 34                           27   \n",
       "8                    57                 25                           37   \n",
       "9                    12                 54                           19   \n",
       "\n",
       "  Physical_Environment_Rank  ... Native_Hawaiian/Other_Pacific_Islander(%)  \\\n",
       "0                        50  ...                                      0.10   \n",
       "1                        62  ...                                      0.07   \n",
       "2                        32  ...                                      0.19   \n",
       "3                        31  ...                                      0.11   \n",
       "4                        53  ...                                      0.12   \n",
       "5                        24  ...                                      0.78   \n",
       "6                         8  ...                                      0.05   \n",
       "7                        41  ...                                      0.11   \n",
       "8                        46  ...                                      0.04   \n",
       "9                        43  ...                                      0.03   \n",
       "\n",
       "  Hispanic(Count)  Hispanic(%)  Non-Hispanic_White_(Count)  \\\n",
       "0          1586.0         2.86                     41336.0   \n",
       "1          9675.0         4.55                    176582.0   \n",
       "2          1063.0         4.21                     11613.0   \n",
       "3           598.0         2.64                     16842.0   \n",
       "4          5549.0         9.57                     50439.0   \n",
       "5           850.0         8.25                      2196.0   \n",
       "6           285.0         1.44                     10229.0   \n",
       "7          4302.0         3.75                     82961.0   \n",
       "8           822.0         2.44                     18710.0   \n",
       "9           425.0         1.64                     23707.0   \n",
       "\n",
       "   Non-Hispanic_White(%)  Female(%) Rural(Count)  Rural(%)  Life_Expectancy  \\\n",
       "0                  74.47      51.34      22921.0     42.00            76.33   \n",
       "1                  83.05      51.45      77060.0     42.28            78.60   \n",
       "2                  45.96      47.23      18613.0     67.79            75.78   \n",
       "3                  74.30      46.45      15663.0     68.35            73.93   \n",
       "4                  86.94      50.69      51562.0     89.95            74.60   \n",
       "5                  21.30      45.53       5607.0     51.37            73.12   \n",
       "6                  51.60      53.43      14921.0     71.23            73.51   \n",
       "7                  72.31      51.93      39955.0     33.70            73.10   \n",
       "8                  55.50      52.13      16816.0     49.15            74.12   \n",
       "9                  91.69      50.32      22282.0     85.74            74.35   \n",
       "\n",
       "   Deaths(Count)  \n",
       "0          815.0  \n",
       "1         2827.0  \n",
       "2          451.0  \n",
       "3          445.0  \n",
       "4         1050.0  \n",
       "5          205.0  \n",
       "6          393.0  \n",
       "7         2333.0  \n",
       "8          691.0  \n",
       "9          575.0  \n",
       "\n",
       "[10 rows x 34 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_merged = df.merge(df2, how='left', on='FIPS')\n",
    "print(df_merged.shape)\n",
    "df_merged.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8f18ad70",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merged = df_merged.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "56645497",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unnamed: 0 has 0 nulls\n",
      "FIPS has 0 nulls\n",
      "State_x has 0 nulls\n",
      "County_x has 0 nulls\n",
      "Lifespan_Rank has 0 nulls\n",
      "Life_Quality_Rank has 0 nulls\n",
      "Health_Behaviors_Rank has 0 nulls\n",
      "Clinical_Care_Rank has 0 nulls\n",
      "Social_Economic_Factors_Rank has 0 nulls\n",
      "Physical_Environment_Rank has 0 nulls\n",
      "County_y has 0 nulls\n",
      "State_y has 0 nulls\n",
      "Lyme_Disease_Incidence_Reported has 0 nulls\n",
      "Population has 0 nulls\n",
      "%<18_Yrs_Old has 0 nulls\n",
      "%65_Yrs_Old_and_over has 0 nulls\n",
      "Income($) has 0 nulls\n",
      "African_American(Count) has 0 nulls\n",
      "African_American(%) has 0 nulls\n",
      "American_Indian/Alaskan_Native(Count) has 0 nulls\n",
      "American_Indian/Alaskan_Native(%) has 0 nulls\n",
      "Asian(Count) has 0 nulls\n",
      "Asian(%) has 0 nulls\n",
      "Native_Hawaiian/Other_Pacific_Islander(Count) has 0 nulls\n",
      "Native_Hawaiian/Other_Pacific_Islander(%) has 0 nulls\n",
      "Hispanic(Count) has 0 nulls\n",
      "Hispanic(%) has 0 nulls\n",
      "Non-Hispanic_White_(Count) has 0 nulls\n",
      "Non-Hispanic_White(%) has 0 nulls\n",
      "Female(%) has 0 nulls\n",
      "Rural(Count) has 0 nulls\n",
      "Rural(%) has 0 nulls\n",
      "Life_Expectancy has 0 nulls\n",
      "Deaths(Count) has 0 nulls\n"
     ]
    }
   ],
   "source": [
    "# Check for null values\n",
    "for col in df_merged:\n",
    "    print(f'{col} has {df_merged[col].isnull().sum()} nulls')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5b1d26f0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_merged = df_merged.drop(columns=['Unnamed: 0','County_y','State_y','State_x','County_x'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8809d83f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merged['Income($)'] = df_merged['Income($)'].str.replace('$', '')\n",
    "df_merged['Income($)'] = df_merged['Income($)'].astype('float') / 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e08aa864",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merged = df_merged.astype({'Lifespan_Rank': 'int32', 'Life_Quality_Rank': 'int32','Health_Behaviors_Rank':'int32',\n",
    "'Clinical_Care_Rank':'int32','Social_Economic_Factors_Rank':'int32','Physical_Environment_Rank':'int32'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a7c0ac7e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FIPS                                               int64\n",
       "Lifespan_Rank                                      int32\n",
       "Life_Quality_Rank                                  int32\n",
       "Health_Behaviors_Rank                              int32\n",
       "Clinical_Care_Rank                                 int32\n",
       "Social_Economic_Factors_Rank                       int32\n",
       "Physical_Environment_Rank                          int32\n",
       "Lyme_Disease_Incidence_Reported                  float64\n",
       "Population                                       float64\n",
       "%<18_Yrs_Old                                     float64\n",
       "%65_Yrs_Old_and_over                             float64\n",
       "Income($)                                        float64\n",
       "African_American(Count)                          float64\n",
       "African_American(%)                              float64\n",
       "American_Indian/Alaskan_Native(Count)            float64\n",
       "American_Indian/Alaskan_Native(%)                float64\n",
       "Asian(Count)                                     float64\n",
       "Asian(%)                                         float64\n",
       "Native_Hawaiian/Other_Pacific_Islander(Count)    float64\n",
       "Native_Hawaiian/Other_Pacific_Islander(%)        float64\n",
       "Hispanic(Count)                                  float64\n",
       "Hispanic(%)                                      float64\n",
       "Non-Hispanic_White_(Count)                       float64\n",
       "Non-Hispanic_White(%)                            float64\n",
       "Female(%)                                        float64\n",
       "Rural(Count)                                     float64\n",
       "Rural(%)                                         float64\n",
       "Life_Expectancy                                  float64\n",
       "Deaths(Count)                                    float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_merged.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9d902f0c",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '../../Data/Cleaned_Data/Ticks_Cases_Lat_Long.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_19300\\1664442087.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdf3\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"../../{file_path}Ticks_Cases_Lat_Long.csv\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mdf3\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\mlenv\\lib\\site-packages\\pandas\\util\\_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    309\u001b[0m                     \u001b[0mstacklevel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mstacklevel\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    310\u001b[0m                 )\n\u001b[1;32m--> 311\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    312\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    313\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\mlenv\\lib\\site-packages\\pandas\\io\\parsers\\readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[0;32m    584\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    585\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 586\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    587\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    588\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\mlenv\\lib\\site-packages\\pandas\\io\\parsers\\readers.py\u001b[0m in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    480\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    481\u001b[0m     \u001b[1;31m# Create the parser.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 482\u001b[1;33m     \u001b[0mparser\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    483\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    484\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\mlenv\\lib\\site-packages\\pandas\\io\\parsers\\readers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m    809\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"has_index_names\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"has_index_names\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    810\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 811\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    812\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    813\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\mlenv\\lib\\site-packages\\pandas\\io\\parsers\\readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[1;34m(self, engine)\u001b[0m\n\u001b[0;32m   1038\u001b[0m             )\n\u001b[0;32m   1039\u001b[0m         \u001b[1;31m# error: Too many arguments for \"ParserBase\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1040\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mmapping\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# type: ignore[call-arg]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1041\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1042\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_failover_to_python\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\mlenv\\lib\\site-packages\\pandas\\io\\parsers\\c_parser_wrapper.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, src, **kwds)\u001b[0m\n\u001b[0;32m     49\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     50\u001b[0m         \u001b[1;31m# open handles\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 51\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_open_handles\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     52\u001b[0m         \u001b[1;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhandles\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     53\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\mlenv\\lib\\site-packages\\pandas\\io\\parsers\\base_parser.py\u001b[0m in \u001b[0;36m_open_handles\u001b[1;34m(self, src, kwds)\u001b[0m\n\u001b[0;32m    227\u001b[0m             \u001b[0mmemory_map\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"memory_map\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    228\u001b[0m             \u001b[0mstorage_options\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"storage_options\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 229\u001b[1;33m             \u001b[0merrors\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"encoding_errors\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"strict\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    230\u001b[0m         )\n\u001b[0;32m    231\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\mlenv\\lib\\site-packages\\pandas\\io\\common.py\u001b[0m in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    705\u001b[0m                 \u001b[0mencoding\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mioargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mencoding\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    706\u001b[0m                 \u001b[0merrors\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 707\u001b[1;33m                 \u001b[0mnewline\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    708\u001b[0m             )\n\u001b[0;32m    709\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '../../Data/Cleaned_Data/Ticks_Cases_Lat_Long.csv'"
     ]
    }
   ],
   "source": [
    "df3 = pd.read_csv(f\"../../{file_path}Ticks_Cases_Lat_Long.csv\")\n",
    "df3.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9a1efe2",
   "metadata": {},
   "outputs": [],
   "source": [
    "mldf = df_merged.merge(df3, on='FIPS')\n",
    "mldf = mldf.drop(columns=['Cases2019','Unnamed: 0'])\n",
    "print(mldf.shape)\n",
    "mldf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a554ca41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for null values\n",
    "for col in mldf:\n",
    "    print(f'{col} has {mldf[col].isnull().sum()} nulls')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80088605",
   "metadata": {},
   "outputs": [],
   "source": [
    "mldf.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e625b714",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Export Merged DF as csv\n",
    "# mldf.to_csv(f\"../../{file_path}/ML_Demographic_LymeCase_HealthRank.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cddf310b",
   "metadata": {},
   "source": [
    "## Split the Data into Training and Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3686a3e2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    2600\n",
       "1     413\n",
       "Name: Ticks_With_Lyme, dtype: int64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create our features\n",
    "X = pd.get_dummies(mldf.drop(columns='Lyme_Disease_Incidence_Reported', axis=1))\n",
    "\n",
    "# Create our target\n",
    "y = mldf['Lyme_Disease_Incidence_Reported']\n",
    "y.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "901e6f5e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2259, 1863)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=1)\n",
    "X_train.shape\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "413a9a46",
   "metadata": {},
   "source": [
    "# Oversampling\n",
    "\n",
    "In this section, you will compare two oversampling algorithms to determine which algorithm results in the best performance. You will oversample the data using the naive random oversampling algorithm and the SMOTE algorithm. For each algorithm, be sure to complete the folliowing steps:\n",
    "\n",
    "1. View the count of the target classes using `Counter` from the collections library. \n",
    "3. Use the resampled data to train a logistic regression model.\n",
    "3. Calculate the balanced accuracy score from sklearn.metrics.\n",
    "4. Print the confusion matrix from sklearn.metrics.\n",
    "5. Generate a classication report using the `imbalanced_classification_report` from imbalanced-learn.\n",
    "\n",
    "Note: Use a random state of 1 for each sampling algorithm to ensure consistency between tests"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e88cc4a",
   "metadata": {},
   "source": [
    "### Naive Random Oversampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "324b340a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({1: 1939, 0: 1939})"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Resample the training data with the RandomOversampler\n",
    "\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "ros = RandomOverSampler(random_state=1)\n",
    "X_resampled, y_resampled = ros.fit_resample(X_train, y_train)\n",
    "Counter(y_resampled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5cffde92",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the Logistic Regression model using the resampled data\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "classifier = LogisticRegression(random_state=1)\n",
    "classifier.fit(X_resampled, y_resampled)\n",
    "y_pred = classifier.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "928db9ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7347480106100795\n"
     ]
    }
   ],
   "source": [
    "# Calculated the balanced accuracy score\n",
    "from sklearn.metrics import accuracy_score\n",
    "print(accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "83e44ec6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>499</td>\n",
       "      <td>162</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>38</td>\n",
       "      <td>55</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     0    1\n",
       "0  499  162\n",
       "1   38   55"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display the confusion matrix\n",
    "from sklearn.metrics import confusion_matrix, classification_report \n",
    "\n",
    "matrix = confusion_matrix(y_test, y_pred)\n",
    "cm_df = pd.DataFrame(\n",
    "    matrix)\n",
    "cm_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "03693e96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   pre       rec       spe        f1       geo       iba       sup\n",
      "\n",
      "          0       0.93      0.75      0.59      0.83      0.67      0.45       661\n",
      "          1       0.25      0.59      0.75      0.35      0.67      0.44        93\n",
      "\n",
      "avg / total       0.85      0.73      0.61      0.77      0.67      0.45       754\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from imblearn.metrics import classification_report_imbalanced \n",
    "print(classification_report_imbalanced(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d22f75e",
   "metadata": {},
   "source": [
    "### SMOTE Oversampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "6de28f4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resample the training data with SMOTE\n",
    "from imblearn.over_sampling import SMOTE\n",
    "X_resampled, y_resampled = SMOTE(random_state=1,\n",
    "sampling_strategy='auto').fit_resample(\n",
    "   X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "3d1022cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the Logistic Regression model using the resampled data\n",
    "classifier = LogisticRegression(random_state=1)\n",
    "classifier.fit(X_resampled, y_resampled)\n",
    "y_pred = classifier.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d4b6f602",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7122015915119363\n"
     ]
    }
   ],
   "source": [
    "# Calculated the balanced accuracy score\n",
    "print(accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "6da009a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>480</td>\n",
       "      <td>181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>36</td>\n",
       "      <td>57</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     0    1\n",
       "0  480  181\n",
       "1   36   57"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display the confusion matrix\n",
    "from sklearn.metrics import confusion_matrix, classification_report \n",
    "\n",
    "matrix = confusion_matrix(y_test, y_pred)\n",
    "cm_df = pd.DataFrame(\n",
    "    matrix)\n",
    "cm_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "ea0c102d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   pre       rec       spe        f1       geo       iba       sup\n",
      "\n",
      "          0       0.93      0.73      0.61      0.82      0.67      0.45       661\n",
      "          1       0.24      0.61      0.73      0.34      0.67      0.44        93\n",
      "\n",
      "avg / total       0.85      0.71      0.63      0.76      0.67      0.45       754\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from imblearn.metrics import classification_report_imbalanced \n",
    "print(classification_report_imbalanced(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f0292de",
   "metadata": {},
   "source": [
    "# Undersampling\n",
    "\n",
    "In this section, you will test an undersampling algorithms to determine which algorithm results in the best performance compared to the oversampling algorithms above. You will undersample the data using the Cluster Centroids algorithm and complete the folliowing steps:\n",
    "\n",
    "1. View the count of the target classes using `Counter` from the collections library. \n",
    "3. Use the resampled data to train a logistic regression model.\n",
    "3. Calculate the balanced accuracy score from sklearn.metrics.\n",
    "4. Print the confusion matrix from sklearn.metrics.\n",
    "5. Generate a classication report using the `imbalanced_classification_report` from imbalanced-learn.\n",
    "\n",
    "Note: Use a random state of 1 for each sampling algorithm to ensure consistency between tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "ce70764d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({0: 320, 1: 320})"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Resample the data using the ClusterCentroids resampler\n",
    "# Warning: This is a large dataset, and this step may take some time to complete\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "rus = RandomUnderSampler(random_state=1)\n",
    "X_resampled, y_resampled = rus.fit_resample(X_train, y_train)\n",
    "Counter(y_resampled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "d18339e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the Logistic Regression model using the resampled data\n",
    "classifier = LogisticRegression(random_state=1)\n",
    "classifier.fit(X_resampled, y_resampled)\n",
    "y_pred = classifier.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "fc05da3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7413793103448276\n"
     ]
    }
   ],
   "source": [
    "# Calculated the balanced accuracy score\n",
    "print(accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "b3b3b9db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>509</td>\n",
       "      <td>152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>43</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     0    1\n",
       "0  509  152\n",
       "1   43   50"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display the confusion matrix\n",
    "from sklearn.metrics import confusion_matrix, classification_report \n",
    "\n",
    "matrix = confusion_matrix(y_test, y_pred)\n",
    "cm_df = pd.DataFrame(\n",
    "    matrix)\n",
    "cm_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "2602dc71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   pre       rec       spe        f1       geo       iba       sup\n",
      "\n",
      "          0       0.92      0.77      0.54      0.84      0.64      0.42       661\n",
      "          1       0.25      0.54      0.77      0.34      0.64      0.40        93\n",
      "\n",
      "avg / total       0.84      0.74      0.57      0.78      0.64      0.42       754\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Print the imbalanced classification report\n",
    "print(classification_report_imbalanced(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0276898d",
   "metadata": {},
   "source": [
    "# Combination (Over and Under) Sampling\n",
    "\n",
    "In this section, you will test a combination over- and under-sampling algorithm to determine if the algorithm results in the best performance compared to the other sampling algorithms above. You will resample the data using the SMOTEENN algorithm and complete the folliowing steps:\n",
    "\n",
    "1. View the count of the target classes using `Counter` from the collections library. \n",
    "3. Use the resampled data to train a logistic regression model.\n",
    "3. Calculate the balanced accuracy score from sklearn.metrics.\n",
    "4. Print the confusion matrix from sklearn.metrics.\n",
    "5. Generate a classication report using the `imbalanced_classification_report` from imbalanced-learn.\n",
    "\n",
    "Note: Use a random state of 1 for each sampling algorithm to ensure consistency between tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "31530a3c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({0: 1661, 1: 2238})"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Resample the training data with SMOTEENN\n",
    "# Warning: This is a large dataset, and this step may take some time to complete\n",
    "from imblearn.combine import SMOTEENN\n",
    "\n",
    "smote_enn = SMOTEENN(random_state=1)\n",
    "X_resampled, y_resampled = smote_enn.fit_resample(X, y)\n",
    "Counter(y_resampled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "fa020a3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the Logistic Regression model using the resampled data\n",
    "model = LogisticRegression(solver='lbfgs', random_state=1)\n",
    "model.fit(X_resampled, y_resampled)\n",
    "y_pred = classifier.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "601f1b1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7413793103448276\n"
     ]
    }
   ],
   "source": [
    "# Calculated the balanced accuracy score\n",
    "print(accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "cd644388",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>509</td>\n",
       "      <td>152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>43</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     0    1\n",
       "0  509  152\n",
       "1   43   50"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display the confusion matrix\n",
    "from sklearn.metrics import confusion_matrix, classification_report \n",
    "\n",
    "matrix = confusion_matrix(y_test, y_pred)\n",
    "cm_df = pd.DataFrame(\n",
    "    matrix)\n",
    "cm_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "e06d2128",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   pre       rec       spe        f1       geo       iba       sup\n",
      "\n",
      "          0       0.92      0.77      0.54      0.84      0.64      0.42       661\n",
      "          1       0.25      0.54      0.77      0.34      0.64      0.40        93\n",
      "\n",
      "avg / total       0.84      0.74      0.57      0.78      0.64      0.42       754\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Print the imbalanced classification report\n",
    "print(classification_report_imbalanced(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7202a495",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlenv",
   "language": "python",
   "name": "mlenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
